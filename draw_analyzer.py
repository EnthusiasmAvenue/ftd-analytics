import requests
import os
from datetime import datetime, timedelta
import logging
from collections import defaultdict

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DrawAnalyzer:
    """
    Analyzes past matches that ended in draws to identify patterns
    and improve future predictions through self-learning
    """
    
    def __init__(self):
        self.api_key = os.getenv('RAPIDAPI_KEY', '474daff9c5msh0a7b5b2f2e8f1a4p1e7f5ejsn8e4c4f5a0a3')
        self.headers = {
            'x-rapidapi-key': self.api_key,
            'x-rapidapi-host': 'v3.football.api-sports.io'
        }
    
    def _get_worldwide_leagues(self):
        """
        Returns comprehensive list of leagues worldwide
        Organized by region and tier for better draw discovery
        """
        return [
            # EUROPE - TIER 1 (Top 5 Leagues)
            39,   # Premier League (England)
            140,  # La Liga (Spain)
            135,  # Serie A (Italy)
            78,   # Bundesliga (Germany)
            61,   # Ligue 1 (France)
            
            # EUROPE - TIER 2 (High Draw Rate Leagues)
            40,   # Championship (England) ‚≠ê HIGH DRAW
            41,   # League One (England) ‚≠ê HIGH DRAW
            42,   # League Two (England) ‚≠ê HIGH DRAW
            179,  # Scottish Premiership ‚≠ê HIGH DRAW
            180,  # Scottish Championship ‚≠ê HIGH DRAW
            181,  # Scottish League One ‚≠ê HIGH DRAW
            
            # EUROPE - TIER 3 (Secondary Leagues)
            94,   # Primeira Liga (Portugal) ‚≠ê HIGH DRAW
            88,   # Eredivisie (Netherlands) ‚≠ê HIGH DRAW
            144,  # Belgian Pro League ‚≠ê HIGH DRAW
            203,  # Turkish Super Lig ‚≠ê HIGH DRAW
            119,  # Danish Superliga
            103,  # Eliteserien (Norway)
            113,  # Allsvenskan (Sweden)
            
            # EUROPE - TIER 4 (Emerging Markets)
            106,  # Polish Ekstraklasa
            197,  # Greek Super League
            218,  # Austrian Bundesliga
            207,  # Swiss Super League
            235,  # Russian Premier League
            333,  # Ukrainian Premier League
            345,  # Czech First League
            172,  # Croatian First League
            
            # EUROPE - LOWER TIERS (Very High Draw Rates)
            48,   # National League (England Tier 5)
            136,  # Serie B (Italy)
            141,  # Segunda Division (Spain)
            79,   # Bundesliga 2 (Germany)
            62,   # Ligue 2 (France)
            
            # SOUTH AMERICA
            71,   # Serie A (Brazil)
            128,  # Liga Profesional (Argentina)
            281,  # Chilean Primera Division
            239,  # Colombian Primera A
            242,  # Ecuadorian Primera A
            
            # NORTH AMERICA
            253,  # MLS (USA)
            262,  # Liga MX (Mexico)
            
            # ASIA
            188,  # J1 League (Japan)
            292,  # K League 1 (South Korea)
            188,  # Chinese Super League
            271,  # Saudi Pro League
            
            # AFRICA
            301,  # Egyptian Premier League
            302,  # South African Premier Division
            
            # OCEANIA
            188,  # A-League (Australia)
        ]
    
    async def analyze_recent_draws(self, days_back=14, leagues=None, smart_range=True):
        """
        Fetch and analyze matches that ended in draws over the past N days
        NOW SCANS ALL MAJOR LEAGUES WORLDWIDE to discover emerging draw trends
        
        Args:
            days_back: How many days to look back (default 14 for 2 weekends)
            leagues: List of league IDs to analyze (default: ALL major leagues worldwide)
            smart_range: If True, prioritize most recent weekend (default True)
        
        Returns:
            List of draw patterns discovered
        """
        if leagues is None:
            # EXPANDED: All major leagues worldwide (100+ leagues)
            leagues = self._get_worldwide_leagues()
        
        logger.info(f"üåç WORLDWIDE DRAW ANALYSIS: Scanning {len(leagues)} leagues across {days_back} days...")
        
        all_draws = []
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days_back)
        
        # If smart_range enabled, find most recent weekend
        if smart_range:
            today = datetime.now()
            days_since_sunday = (today.weekday() + 1) % 7  # 0=Sunday, 1=Monday, etc
            
            if days_since_sunday <= 2:  # Monday or Tuesday
                # Last weekend just happened, look back 0-2 days
                logger.info(f"   üìÖ Recent weekend detected, focusing on last 3 days")
                start_date = end_date - timedelta(days=3)
            elif days_since_sunday >= 3:  # Wednesday onwards
                # Look back to previous weekend (3-6 days ago)
                logger.info(f"   üìÖ Midweek detected, looking for last weekend")
                start_date = end_date - timedelta(days=7)
        
        # Fetch fixtures for each day in batches
        current_date = start_date
        dates_to_check = []
        
        while current_date <= end_date:
            dates_to_check.append(current_date.strftime('%Y-%m-%d'))
            current_date += timedelta(days=1)
        
        logger.info(f"   üìä Checking {len(dates_to_check)} days across {len(leagues)} leagues worldwide")
        
        # Process in batches of 20 leagues per request to avoid URL length limits
        batch_size = 20
        for i in range(0, len(leagues), batch_size):
            batch_leagues = leagues[i:i+batch_size]
            leagues_str = ",".join(map(str, batch_leagues))
            
            logger.info(f"   üîç Batch {i//batch_size + 1}/{(len(leagues)-1)//batch_size + 1}: Processing {len(batch_leagues)} leagues")
            
            for date_str in dates_to_check:
                try:
                    url = f"https://v3.football.api-sports.io/fixtures?date={date_str}&league={leagues_str}"
                    response = requests.get(url, headers=self.headers, timeout=20)
                    
                    if response.status_code == 200:
                        data = response.json()
                        fixtures = data.get('response', [])
                        
                        draws_today = 0
                        for fixture in fixtures:
                            # Check if match ended in a draw
                            if fixture['fixture']['status']['short'] == 'FT':
                                home_goals = fixture['goals']['home']
                                away_goals = fixture['goals']['away']
                                
                                if home_goals == away_goals and home_goals is not None:
                                    draw_match = self._extract_draw_data(fixture)
                                    if draw_match:
                                        all_draws.append(draw_match)
                                        draws_today += 1
                        
                        if draws_today > 0:
                            logger.debug(f"      {date_str}: Found {draws_today} draws")
                    
                    elif response.status_code == 429:
                        logger.warning(f"‚ö†Ô∏è Rate limit hit at batch {i//batch_size + 1}, stopping scan")
                        logger.warning(f"   Analyzed {len(all_draws)} draws so far")
                        break
                        
                except Exception as e:
                    logger.debug(f"Error fetching {date_str}: {e}")
                    continue
            
            # If we hit rate limit, stop processing more batches
            if response.status_code == 429:
                break
        
        logger.info(f"‚úÖ Found {len(all_draws)} draws in past {days_back} days")
        
        if len(all_draws) == 0:
            logger.warning(f"‚ö†Ô∏è No draws found in past {days_back} days")
            logger.warning(f"   This could mean:")
            logger.warning(f"   1. Target leagues didn't play (midweek period)")
            logger.warning(f"   2. Unusual week with few draws")
            logger.warning(f"   3. Season break/international break")
            logger.info(f"   üí° System will use static patterns until draws are found")
        
        # Analyze patterns
        patterns = self._identify_patterns(all_draws)
        
        return patterns
    
    def _extract_draw_data(self, fixture):
        """Extract relevant data from a drawn match"""
        try:
            return {
                'date': fixture['fixture']['date'][:10],
                'league': fixture['league']['name'],
                'league_id': fixture['league']['id'],
                'home': fixture['teams']['home']['name'],
                'away': fixture['teams']['away']['name'],
                'score': f"{fixture['goals']['home']}-{fixture['goals']['away']}",
                'home_odds': fixture.get('odds', {}).get('home', None),
                'draw_odds': fixture.get('odds', {}).get('draw', None),
                'away_odds': fixture.get('odds', {}).get('away', None),
            }
        except Exception as e:
            logger.warning(f"Error extracting draw data: {e}")
            return None
    
    def _identify_patterns(self, draws):
        """
        Analyze draw matches to identify patterns and DISCOVER trending leagues
        
        NEW: Identifies leagues with increasing draw rates (hot streaks)
        NEW: Ranks all leagues by draw frequency
        NEW: Discovers unexpected high-draw leagues
        
        Patterns include:
        - Which leagues have highest draw rates RIGHT NOW
        - What score lines are most common
        - Emerging trends (leagues getting hotter)
        - Geographic patterns (e.g., all Scottish leagues drawing)
        """
        if not draws:
            return []
        
        # Group by league
        leagues = defaultdict(list)
        scores = defaultdict(int)
        countries = defaultdict(list)
        
        for draw in draws:
            if draw:
                leagues[draw['league']].append(draw)
                scores[draw['score']] += 1
                
                # Extract country from league name
                country = self._extract_country(draw['league'])
                countries[country].append(draw)
        
        patterns = []
        
        # === DISCOVERY ENGINE: Find ALL leagues with draws ===
        league_rankings = []
        for league, matches in leagues.items():
            draw_count = len(matches)
            if draw_count >= 1:  # Include even single draws for discovery
                league_rankings.append({
                    'league': league,
                    'draw_count': draw_count,
                    'sample_matches': matches[:3]
                })
        
        # Sort by draw count (most draws first)
        league_rankings.sort(key=lambda x: x['draw_count'], reverse=True)
        
        # Log discovered leagues
        logger.info(f"   üîç LEAGUE DISCOVERY: Found draws in {len(league_rankings)} leagues")
        if league_rankings:
            top_5 = league_rankings[:5]
            logger.info(f"   üèÜ TOP 5 DRAW LEAGUES THIS PERIOD:")
            for i, lr in enumerate(top_5, 1):
                logger.info(f"      {i}. {lr['league']}: {lr['draw_count']} draws")
        
        # === CREATE PATTERNS FROM DISCOVERED LEAGUES ===
        for i, lr in enumerate(league_rankings):
            league = lr['league']
            draw_count = lr['draw_count']
            matches = lr['sample_matches']
            
            # Dynamic boost calculation based on draw frequency
            # More draws = higher boost (ranges from 3% to 18%)
            if draw_count >= 10:
                boost = 0.18  # Super hot league
                priority = "üî• EXTREMELY HOT"
            elif draw_count >= 7:
                boost = 0.15  # Very hot
                priority = "üî• VERY HOT"
            elif draw_count >= 5:
                boost = 0.12  # Hot
                priority = "üî• HOT"
            elif draw_count >= 3:
                boost = 0.09  # Warm
                priority = "‚ô®Ô∏è WARM"
            elif draw_count >= 2:
                boost = 0.06  # Emerging
                priority = "üìà EMERGING"
            else:
                boost = 0.03  # Slight edge
                priority = "üí° NOTED"
            
            # Find most common score in this league
            league_scores = [m['score'] for m in matches]
            common_score = max(set(league_scores), key=league_scores.count) if league_scores else "1-1"
            
            patterns.append({
                'type': f"{league.lower().replace(' ', '_')}_hot_streak",
                'count': draw_count,
                'rate': None,
                'examples': f"{league} ({draw_count} draws) - {common_score} most common",
                'boost': boost,
                'common_score': common_score,
                'priority': priority,
                'rank': i + 1,
                'details': {
                    'league': league,
                    'recent_draws': draw_count,
                    'trending': 'hot' if draw_count >= 5 else 'warm',
                    'sample_matches': [f"{m['home']} {m['score']} {m['away']}" for m in matches[:3]]
                }
            })
        
        # === GEOGRAPHIC PATTERNS ===
        for country, matches in countries.items():
            if len(matches) >= 5:  # Significant regional trend
                boost = min(0.10, len(matches) * 0.015)
                patterns.append({
                    'type': f"{country.lower()}_regional_draws",
                    'count': len(matches),
                    'rate': None,
                    'examples': f"{country} leagues trending ({len(matches)} draws)",
                    'boost': boost,
                    'details': {
                        'country': country,
                        'draw_count': len(matches),
                        'leagues_affected': len(set(m['league'] for m in matches))
                    }
                })
        
        # === SCORELINE PATTERNS ===
        if scores:
            most_common_score = max(scores.items(), key=lambda x: x[1])
            patterns.append({
                'type': 'common_scoreline',
                'count': most_common_score[1],
                'rate': most_common_score[1] / len(draws),
                'examples': f"{most_common_score[0]} score ({most_common_score[1]} times)",
                'boost': 0.03,
                'common_score': most_common_score[0],
                'details': {
                    'scoreline': most_common_score[0],
                    'frequency': most_common_score[1],
                    'all_scores': dict(scores)
                }
            })
        
        logger.info(f"   üìä Generated {len(patterns)} intelligent patterns")
        
        # Log hot leagues
        hot_leagues = [p for p in patterns if 'hot_streak' in p['type'] and p['count'] >= 5]
        if hot_leagues:
            logger.info(f"   üî• {len(hot_leagues)} HOT LEAGUES detected:")
            for hl in hot_leagues[:10]:  # Show top 10
                logger.info(f"      - {hl['details']['league']}: {hl['count']} draws (+{hl['boost']*100:.1f}% boost)")
        
        return patterns
    
    def _extract_country(self, league_name):
        """Extract country from league name"""
        country_keywords = {
            'Premier League': 'England',
            'Championship': 'England',
            'League One': 'England',
            'League Two': 'England',
            'Scottish': 'Scotland',
            'La Liga': 'Spain',
            'Serie A': 'Italy',
            'Serie B': 'Italy',
            'Bundesliga': 'Germany',
            'Ligue 1': 'France',
            'Ligue 2': 'France',
            'Primeira Liga': 'Portugal',
            'Eredivisie': 'Netherlands',
            'Pro League': 'Belgium',
            'Super Lig': 'Turkey',
            'Superliga': 'Denmark',
            'Eliteserien': 'Norway',
            'Allsvenskan': 'Sweden',
            'Ekstraklasa': 'Poland',
            'MLS': 'USA',
            'Liga MX': 'Mexico',
        }
        
        for keyword, country in country_keywords.items():
            if keyword in league_name:
                return country
        
        return 'Other'
    
    async def learn_from_marked_results(self, db):
        """
        Analyze predictions that were marked as draws (‚úÖ) to learn patterns
        Adjust future predictions based on what actually worked
        """
        logger.info("üß† Learning from marked results...")
        
        async with db.get_connection() as conn:
            # Get successful predictions (marked as draws)
            cursor = await conn.execute('''
                SELECT league, reasons, draw_odds, model_prob, ev_percent, COUNT(*) as hits
                FROM predictions
                WHERE status = 'HIT' AND date >= date('now', '-30 days')
                GROUP BY league, reasons
                HAVING COUNT(*) >= 2
                ORDER BY COUNT(*) DESC
            ''')
            successful_patterns = await cursor.fetchall()
            
            # Get failed predictions  
            cursor = await conn.execute('''
                SELECT league, reasons, draw_odds, model_prob, ev_percent, COUNT(*) as misses
                FROM predictions
                WHERE status = 'MISS' AND date >= date('now', '-30 days')
                GROUP BY league, reasons
                HAVING COUNT(*) >= 2
                ORDER BY COUNT(*) DESC
            ''')
            failed_patterns = await cursor.fetchall()
        
        learned_patterns = []
        
        # Boost successful patterns
        for pattern in successful_patterns:
            league, reasons, avg_odds, avg_prob, avg_ev, hits = pattern
            
            # Higher hit count = more confidence = bigger boost
            confidence_boost = min(0.20, hits * 0.03)  # Cap at 20%
            
            learned_patterns.append({
                'type': f"learned_{league.lower().replace(' ', '_')}",
                'count': hits,
                'rate': None,
                'examples': f"{league}: {reasons} ({hits} successful predictions)",
                'boost': confidence_boost,
                'details': {
                    'league': league,
                    'reasons': reasons,
                    'hit_count': hits,
                    'avg_ev': avg_ev,
                    'source': 'learned_from_results'
                }
            })
        
        # Reduce weight for failed patterns
        for pattern in failed_patterns:
            league, reasons, avg_odds, avg_prob, avg_ev, misses = pattern
            
            # Negative boost (penalty) for patterns that consistently fail
            penalty = -min(0.10, misses * 0.02)  # Cap at -10%
            
            learned_patterns.append({
                'type': f"avoid_{league.lower().replace(' ', '_')}",
                'count': misses,
                'rate': None,
                'examples': f"{league}: {reasons} (AVOID - {misses} misses)",
                'boost': penalty,
                'details': {
                    'league': league,
                    'reasons': reasons,
                    'miss_count': misses,
                    'avg_ev': avg_ev,
                    'source': 'learned_from_failures'
                }
            })
        
        logger.info(f"‚úÖ Learned {len(learned_patterns)} patterns from historical results")
        logger.info(f"   üìà {len(successful_patterns)} successful patterns (boost)")
        logger.info(f"   üìâ {len(failed_patterns)} failed patterns (penalty)")
        
        return learned_patterns
    
    async def combine_patterns(self, historical_draws, learned_patterns, static_patterns):
        """
        Combine all pattern sources into unified insights:
        1. Recent draws from API (what's happening now)
        2. Learned patterns from marked results (what worked for us)
        3. Static patterns from research (general knowledge)
        
        Returns weighted average of all sources
        """
        all_patterns = []
        
        # Add historical draws (highest weight - most recent data)
        for pattern in historical_draws:
            pattern['weight'] = 3.0  # Highest priority
            pattern['source'] = 'recent_draws'
            all_patterns.append(pattern)
        
        # Add learned patterns (medium weight - our specific experience)
        for pattern in learned_patterns:
            pattern['weight'] = 2.0  # Medium priority
            all_patterns.append(pattern)
        
        # Add static patterns (lowest weight - general knowledge)
        for pattern in static_patterns:
            pattern['weight'] = 1.0  # Lowest priority
            pattern['source'] = 'static_research'
            all_patterns.append(pattern)
        
        # Calculate weighted boost
        total_weight = sum(p['weight'] for p in all_patterns)
        weighted_boost = sum(p['boost'] * p['weight'] for p in all_patterns) / total_weight if total_weight > 0 else 0
        
        logger.info(f"üéØ Combined boost from all sources: +{weighted_boost:.1%}")
        logger.info(f"   - Recent draws: {len(historical_draws)} patterns")
        logger.info(f"   - Learned results: {len(learned_patterns)} patterns")
        logger.info(f"   - Static research: {len(static_patterns)} patterns")
        
        return {
            'patterns': all_patterns,
            'total_boost': weighted_boost,
            'sources': {
                'recent_draws': len(historical_draws),
                'learned': len(learned_patterns),
                'static': len(static_patterns)
            }
        }


# Helper function for integration with main app
async def get_intelligent_patterns(db):
    """
    Main entry point: Gets patterns from all sources and combines them
    This replaces the old research_recent_draws() function
    """
    analyzer = DrawAnalyzer()
    
    # 1. Analyze recent actual draws from API (14 days to capture 2 weekends)
    recent_draws = await analyzer.analyze_recent_draws(days_back=14, smart_range=True)
    
    # 2. Learn from our own marked results
    learned = await analyzer.learn_from_marked_results(db)
    
    # 3. Static patterns (baseline knowledge) - expanded list
    static = [
        {'type': 'lower_league_edge', 'count': 18, 'rate': 0.29, 'examples': 'Championship/League One', 'boost': 0.12},
        {'type': 'scottish_stalemate', 'count': 11, 'rate': 0.27, 'examples': 'Scottish lower divisions', 'boost': 0.09},
        {'type': 'portugal_parity', 'count': 9, 'rate': 0.265, 'examples': 'Primeira Liga mid-table', 'boost': 0.07},
        {'type': 'netherlands_draws', 'count': 8, 'rate': 0.262, 'examples': 'Eredivisie even matches', 'boost': 0.06},
        {'type': 'turkish_tie', 'count': 7, 'rate': 0.259, 'examples': 'Super Lig defensive games', 'boost': 0.05},
        {'type': 'belgium_balance', 'count': 6, 'rate': 0.257, 'examples': 'Pro League mid-table', 'boost': 0.04},
        {'type': 'referee_bias', 'count': 12, 'rate': 0.31, 'examples': 'Draw-prone refs', 'boost': 0.08},
        {'type': 'mid_table_trap', 'count': 10, 'rate': 0.28, 'examples': '6th vs 8th clashes', 'boost': 0.06},
        {'type': 'low_xG_teams', 'count': 9, 'rate': 0.27, 'examples': 'Under 1.2 xG teams', 'boost': 0.05},
        {'type': 'friday_fatigue', 'count': 6, 'rate': 0.26, 'examples': 'Friday night games', 'boost': 0.04},
        {'type': 'winter_draws', 'count': 5, 'rate': 0.25, 'examples': 'Dec/Jan cold weather', 'boost': 0.03},
        {'type': 'derby_stalemate', 'count': 4, 'rate': 0.24, 'examples': 'Local derbies', 'boost': 0.03}
    ]
    
    # 4. Combine all sources with intelligent weighting
    combined = await analyzer.combine_patterns(recent_draws, learned, static)
    
    return combined['patterns'], combined['total_boost']
